{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"anaconda-cloud":{},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mudasarsabir/cnn-based-image-classification-on-cifar-10-dataset?scriptVersionId=251090656\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Artificial Intelligence Nanodegree\n\n## Convolutional Neural Networks\n\n---\n\nIn this notebook, we train a CNN on augmented images from the CIFAR-10 database.\n\n### 1. Load CIFAR-10 Database","metadata":{"id":"1gOfhwSf1WPy"}},{"cell_type":"code","source":"import keras\nfrom keras.datasets import cifar10\n\n# load the pre-shuffled train and test data\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()","metadata":{"id":"yaUw84CD1WP7","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:24:47.556741Z","iopub.execute_input":"2025-07-17T13:24:47.556996Z","iopub.status.idle":"2025-07-17T13:25:05.98031Z","shell.execute_reply.started":"2025-07-17T13:24:47.556977Z","shell.execute_reply":"2025-07-17T13:25:05.979671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\n\nprint(x_test.shape)\nprint(y_test.shape)","metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1752665310250,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"},"user_tz":-300},"id":"d8cCAE0I1WQA","outputId":"1ae39c74-5e72-4e41-8cfa-a857fe5d0dd8","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:05.981274Z","iopub.execute_input":"2025-07-17T13:25:05.981663Z","iopub.status.idle":"2025-07-17T13:25:05.986168Z","shell.execute_reply.started":"2025-07-17T13:25:05.981647Z","shell.execute_reply":"2025-07-17T13:25:05.985508Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. Visualize the First 24 Training Images","metadata":{"id":"I705doNh1WQD"}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfig = plt.figure(figsize=(20,5))\nfor i in range(36):\n    ax = fig.add_subplot(3, 12, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_train[i]))","metadata":{"executionInfo":{"elapsed":736,"status":"ok","timestamp":1752665310989,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"},"user_tz":-300},"id":"GwFm8ezF1WQE","outputId":"b8ed9450-5be5-4dda-de6f-fe644f0821f8","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:05.987007Z","iopub.execute_input":"2025-07-17T13:25:05.987264Z","iopub.status.idle":"2025-07-17T13:25:07.065086Z","shell.execute_reply.started":"2025-07-17T13:25:05.987241Z","shell.execute_reply":"2025-07-17T13:25:07.064264Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3. Rescale the Images by Dividing Every Pixel in Every Image by 255","metadata":{"id":"gaZFd70C1WQF"}},{"cell_type":"code","source":"# rescale [0,255] --> [0,1]\nx_train = x_train.astype('float32')/255\nx_test = x_test.astype('float32')/255","metadata":{"id":"laBUfF7f1WQG","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:07.066489Z","iopub.execute_input":"2025-07-17T13:25:07.066718Z","iopub.status.idle":"2025-07-17T13:25:07.454293Z","shell.execute_reply.started":"2025-07-17T13:25:07.066701Z","shell.execute_reply":"2025-07-17T13:25:07.453661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# x_train[5]","metadata":{"id":"FC_cfBvH4asW","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:07.454969Z","iopub.execute_input":"2025-07-17T13:25:07.455187Z","iopub.status.idle":"2025-07-17T13:25:07.458899Z","shell.execute_reply.started":"2025-07-17T13:25:07.455169Z","shell.execute_reply":"2025-07-17T13:25:07.458076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = len(np.unique(y_train))\nnum_classes","metadata":{"id":"bDk1ogg5960G","executionInfo":{"status":"ok","timestamp":1752665311282,"user_tz":-300,"elapsed":19,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"}},"outputId":"56c11878-73f2-4894-c5b2-9b1fad7a29e5","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:07.459586Z","iopub.execute_input":"2025-07-17T13:25:07.459872Z","iopub.status.idle":"2025-07-17T13:25:07.477607Z","shell.execute_reply.started":"2025-07-17T13:25:07.459852Z","shell.execute_reply":"2025-07-17T13:25:07.476947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.unique(y_train)","metadata":{"executionInfo":{"elapsed":51,"status":"ok","timestamp":1752665322339,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"},"user_tz":-300},"id":"Or2ZKhm81WQI","outputId":"78b8a618-f486-473b-9f7c-55a4ea43de41","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:07.478467Z","iopub.execute_input":"2025-07-17T13:25:07.478882Z","iopub.status.idle":"2025-07-17T13:25:07.491962Z","shell.execute_reply.started":"2025-07-17T13:25:07.478863Z","shell.execute_reply":"2025-07-17T13:25:07.491185Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.  Break Dataset into Training, Testing, and Validation Sets","metadata":{"id":"S532q9JF1WQH"}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nimport tensorflow as tf\n\n# break training set into training and validation sets\n(x_train, x_valid) = x_train[5000:], x_train[:5000]\n(y_train, y_valid) = y_train[5000:], y_train[:5000]\n\n# one-hot encode the labels\nnum_classes = len(np.unique(y_train))\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)\ny_valid = to_categorical(y_valid, num_classes)#y_valid = tf.keras.utils.to_categorical(y_valid, num_classes)\n\n# print shape of training set\nprint('x_train shape:', x_train.shape)\nprint('x_valid shape:', x_valid.shape)\nprint('y_train shape:', y_train.shape)\nprint('y_valid shape:', y_valid.shape,\"\\n\")\n\n# print number of training, validation, and test images\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint(x_valid.shape[0], 'validation samples')","metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1752665325616,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"},"user_tz":-300},"id":"g_BIzTiy1WQJ","outputId":"0166395d-954e-4f2a-95d5-e78017218db8","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:07.492989Z","iopub.execute_input":"2025-07-17T13:25:07.493197Z","iopub.status.idle":"2025-07-17T13:25:07.565496Z","shell.execute_reply.started":"2025-07-17T13:25:07.493174Z","shell.execute_reply":"2025-07-17T13:25:07.564696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train","metadata":{"id":"IimaWF0f83V6","executionInfo":{"status":"ok","timestamp":1752665328066,"user_tz":-300,"elapsed":12,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"}},"outputId":"f177dd0e-1feb-4a54-d837-4f7f983baeba","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:07.566298Z","iopub.execute_input":"2025-07-17T13:25:07.566542Z","iopub.status.idle":"2025-07-17T13:25:07.571362Z","shell.execute_reply.started":"2025-07-17T13:25:07.56652Z","shell.execute_reply":"2025-07-17T13:25:07.570819Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5. Create and Configure Augmented Image Generator","metadata":{"id":"hmqrtKPJ1WQK"}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# create and configure augmented image generator\ndatagen_train = ImageDataGenerator(\n    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n    horizontal_flip=True) # randomly flip images horizontally\n\n# fit augmented image generator on data\n#datagen_train.fit(x_train)","metadata":{"id":"L5fd8aMb1WQK","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:07.573726Z","iopub.execute_input":"2025-07-17T13:25:07.573969Z","iopub.status.idle":"2025-07-17T13:25:07.588945Z","shell.execute_reply.started":"2025-07-17T13:25:07.573952Z","shell.execute_reply":"2025-07-17T13:25:07.588131Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 6. Visualize Original and Augmented Images","metadata":{"id":"4NFjRULd1WQL"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# take subset of training data\nx_train_subset = x_train[:12]\n\n# visualize subset of training data\nfig = plt.figure(figsize=(20,2))\nfor i in range(0, len(x_train_subset)):\n    ax = fig.add_subplot(1, 12, i+1)\n    ax.imshow(x_train_subset[i])\nfig.suptitle('Subset of Original Training Images', fontsize=20)\nplt.show()\n\n# visualize augmented images\nfig = plt.figure(figsize=(20,2))\nfor x_batch in datagen_train.flow(x_train_subset, batch_size=12):\n    for i in range(0, 12):\n        ax = fig.add_subplot(1, 12, i+1)\n        ax.imshow(x_batch[i])\n    fig.suptitle('Augmented Images', fontsize=20)\n    plt.show()\n    break;","metadata":{"executionInfo":{"elapsed":1352,"status":"ok","timestamp":1752665839069,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"},"user_tz":-300},"id":"YjG0ri8d1WQL","outputId":"64fb68ae-fa25-48d9-952b-8a729811f739","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:07.589817Z","iopub.execute_input":"2025-07-17T13:25:07.590087Z","iopub.status.idle":"2025-07-17T13:25:09.070269Z","shell.execute_reply.started":"2025-07-17T13:25:07.590063Z","shell.execute_reply":"2025-07-17T13:25:09.069693Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 7. Define the Model Architecture","metadata":{"id":"qtbzCZUF1WQM"}},{"cell_type":"code","source":"date_shape = x_train.shape[1:]\ndate_shape","metadata":{"id":"KraZrlqqA3qe","executionInfo":{"status":"ok","timestamp":1752665902847,"user_tz":-300,"elapsed":19,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"}},"outputId":"66fbdf92-a21b-4e83-c439-c4cac5cea577","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:09.070964Z","iopub.execute_input":"2025-07-17T13:25:09.071193Z","iopub.status.idle":"2025-07-17T13:25:09.075722Z","shell.execute_reply.started":"2025-07-17T13:25:09.071177Z","shell.execute_reply":"2025-07-17T13:25:09.075222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, DepthwiseConv2D, Flatten, MaxPooling2D, Activation, LeakyReLU, Dropout, BatchNormalization, GlobalAveragePooling2D, Input\nfrom keras.optimizers import Adam\n\nmodel = Sequential()\n\n# Changed nb_filter to filters, nb_row/nb_col to kernel_size, and border_mode to padding\n\n# 1st Conv Block\nmodel.add(Input(shape=date_shape))\nmodel.add(DepthwiseConv2D(kernel_size=(3, 3), padding='same', use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n# 2st Conv Block\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.1))\n# model.add(LeakyReLU(negative_slope=0.01))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.25)) # Drop 25% of neurons\n\n# 3nd Conv Block\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', use_bias=False)) #32 â†’ 64 â†’ 128\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 4rd Conv Block\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), padding='same', use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Dense Layers\nmodel.add(Flatten())\n\n# If your last Conv2D output is (batch_size, 8, 8, 20)\n# â†’ GlobalAveragePooling2D() will give (batch_size, 20) instead of (batch_size, 8*8*20 = 1280) like Flatten does.\n# Thatâ€™s a huge reduction in parameters before the dense layers.\n# model.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(units=100, use_bias=False)) #units are neurons\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))  # Drop 30%\n\nmodel.add(Dense(units=50, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n\n# model.add(Dense(units=10, activation='softmax'))  # Changed to 10 units and softmax for 10 classes\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.summary()\n","metadata":{"executionInfo":{"elapsed":340,"status":"ok","timestamp":1752665905056,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"},"user_tz":-300},"id":"Bqc8YoJc1WQM","outputId":"0ee325fb-9bbb-47ae-ff9a-3e0688d381a3","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:09.076364Z","iopub.execute_input":"2025-07-17T13:25:09.07655Z","iopub.status.idle":"2025-07-17T13:25:11.537401Z","shell.execute_reply.started":"2025-07-17T13:25:09.076531Z","shell.execute_reply":"2025-07-17T13:25:11.536885Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 8. Compile the Model","metadata":{"id":"2dY9ru9N1WQM"}},{"cell_type":"code","source":"# compile the model\nlearning_rate = 0.0001\nopt = Adam(learning_rate=learning_rate)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt,\n                  metrics=['accuracy'])","metadata":{"id":"a5GY2elh1WQN","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:11.538053Z","iopub.execute_input":"2025-07-17T13:25:11.538284Z","iopub.status.idle":"2025-07-17T13:25:11.550431Z","shell.execute_reply.started":"2025-07-17T13:25:11.538259Z","shell.execute_reply":"2025-07-17T13:25:11.549718Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 9. Train the Model","metadata":{"id":"NMtGxcwU1WQP"}},{"cell_type":"code","source":"# print(45000*3)\n# print((x_train.shape[0] // 32)*100)\n# keras.__version__","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1752665922677,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"},"user_tz":-300},"id":"ICjZzqSu1WQQ","outputId":"15c64525-931d-4e41-dde4-9874ea2a86e9","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:25:11.551035Z","iopub.execute_input":"2025-07-17T13:25:11.551238Z","iopub.status.idle":"2025-07-17T13:25:11.558608Z","shell.execute_reply.started":"2025-07-17T13:25:11.551224Z","shell.execute_reply":"2025-07-17T13:25:11.558155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"rp3m8jWk1WQR","executionInfo":{"status":"ok","timestamp":1752675349554,"user_tz":-300,"elapsed":3075288,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"}},"outputId":"b27e789f-3a7b-4c28-900f-2168289a441f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import load_model\n\n# Assumes: model, datagen_train, x_train, y_train, x_valid, y_valid are already defined\n\nbatch_size = 5000\nmax_epochs = 100\npatience_limit = 5  # Optional: stop if val_loss doesn't improve after N tries\nbest_val_loss = np.Inf\npatience = 0\nepoch = 0\n\n# Float32 conversion (as you had)\nx_train = x_train.astype('float32')\nx_valid = x_valid.astype('float32')\n\n# Setup model checkpoint\ncheckpointer = ModelCheckpoint(\n    filepath='aug_model_best.keras',\n    verbose=1,\n    save_best_only=True\n)\n\nprint(\"\\nðŸš€ Starting feedback-controlled training...\\n\")\n\nwhile epoch < max_epochs and patience < patience_limit:\n    print(f\"\\nðŸ” Epoch {epoch+1} (trying until val_loss improves)\")\n\n    # Train one epoch manually\n    history = model.fit(\n        datagen_train.flow(x_train, y_train, batch_size=batch_size),\n        steps_per_epoch=len(x_train) // batch_size,\n        epochs=1,\n        verbose=2,\n        callbacks=[checkpointer],\n        validation_data=(x_valid, y_valid),\n        validation_steps=len(x_valid) // batch_size\n    )\n\n    val_loss = history.history['val_loss'][0]\n\n    # Check validation loss\n    if val_loss < best_val_loss:\n        print(f\"âœ… Validation loss improved: {best_val_loss:.4f} â†’ {val_loss:.4f}\")\n        best_val_loss = val_loss\n        patience = 0\n        epoch += 1\n    else:\n        patience += 1\n        print(f\"âš ï¸ No improvement in validation loss. Patience {patience}/{patience_limit}\")\n\nprint(\"\\nðŸ Training finished. Best validation loss:\", best_val_loss)\n\n# Optional: Load best model\n# model = load_model('aug_model_best.keras')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T13:32:22.967249Z","iopub.execute_input":"2025-07-17T13:32:22.967992Z","iopub.status.idle":"2025-07-17T13:34:46.287697Z","shell.execute_reply.started":"2025-07-17T13:32:22.967968Z","shell.execute_reply":"2025-07-17T13:34:46.287129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (Dense, Conv2D, DepthwiseConv2D, Flatten, MaxPooling2D,\n                                     Activation, LeakyReLU, Dropout, BatchNormalization, Input)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.datasets import cifar10\n\n# ------------------- Load & Preprocess Data --------------------\n(x_train, y_train), (x_valid, y_valid) = cifar10.load_data()\nnum_classes = len(np.unique(y_train))\nx_train = x_train.astype('float32') / 255.0\nx_valid = x_valid.astype('float32') / 255.0\ny_train = to_categorical(y_train, num_classes)\ny_valid = to_categorical(y_valid, num_classes)\ninput_shape = x_train.shape[1:]\n\n# ------------------- Data Augmentation --------------------\ndatagen_train = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True\n)\ndatagen_train.fit(x_train)\n\n# ------------------- Model Definition --------------------\nmodel = Sequential()\nmodel.add(Input(shape=input_shape))\nmodel.add(DepthwiseConv2D(kernel_size=(3, 3), padding='same', use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), padding='same', use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(100, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(50, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# ------------------- Compile --------------------\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# ------------------- Callbacks --------------------\ncheckpointer = ModelCheckpoint(\n    filepath='aug_model_best.keras',\n    verbose=1,\n    save_best_only=True\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=2,\n    min_lr=1e-6,\n    verbose=1\n)\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopper = EarlyStopping(\n    monitor='val_loss',\n    patience=7,\n    restore_best_weights=True,\n    verbose=1\n)\n\n\ncsv_logger = CSVLogger('training_log.csv', append=True)\n\nfrom tensorflow.keras.callbacks import TensorBoard\n\ntensorboard = TensorBoard(log_dir='./logs', histogram_freq=1)\n\ncallbacks = [checkpointer, lr_scheduler, csv_logger, tensorboard, early_stopper]\n\n# ------------------- Feedback Training Loop --------------------\nbatch_size = 128\nmax_epochs = 100\npatience_limit = 5\nbest_val_loss = np.Inf\npatience = 0\nepoch = 0\n\nprint(\"\\nðŸš€ Starting feedback-controlled training...\\n\")\n\nwhile epoch < max_epochs and patience < patience_limit:\n    print(f\"\\nðŸ” Epoch {epoch+1} (retry until val_loss improves)\")\n\n    history = model.fit(\n        datagen_train.flow(x_train, y_train, batch_size=batch_size, shuffle=True),\n        steps_per_epoch=len(x_train) // batch_size,\n        epochs=1,\n        verbose=2,\n        callbacks=callbacks,\n        validation_data=(x_valid, y_valid),\n        validation_steps=len(x_valid) // batch_size\n    )\n\n    val_loss = history.history['val_loss'][0]\n\n    if val_loss < best_val_loss:\n        print(f\"âœ… val_loss improved: {best_val_loss:.4f} â†’ {val_loss:.4f}\")\n        best_val_loss = val_loss\n        patience = 0\n        epoch += 1\n    else:\n        patience += 1\n        print(f\"âš ï¸ val_loss did not improve. Patience {patience}/{patience_limit}\")\n\nprint(f\"\\nðŸ Finished training. Best val_loss: {best_val_loss:.4f}\")\n\n# # ------------------- Optional: Plot Training Curve --------------------\n# df_log = pd.read_csv('training_log.csv')\n\n# plt.figure(figsize=(12, 6))\n# plt.subplot(1, 2, 1)\n# plt.plot(df_log['epoch'], df_log['loss'], label='Train Loss')\n# plt.plot(df_log['epoch'], df_log['val_loss'], label='Val Loss')\n# plt.xlabel('Epoch')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.title('Loss over Epochs')\n\n# plt.subplot(1, 2, 2)\n# plt.plot(df_log['epoch'], df_log['accuracy'], label='Train Acc')\n# plt.plot(df_log['epoch'], df_log['val_accuracy'], label='Val Acc')\n# plt.xlabel('Epoch')\n# plt.ylabel('Accuracy')\n# plt.legend()\n# plt.title('Accuracy over Epochs')\n\n# plt.tight_layout()\n# plt.savefig(\"training_plot.png\")\n# plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T14:42:15.448454Z","iopub.execute_input":"2025-07-17T14:42:15.449073Z","iopub.status.idle":"2025-07-17T14:51:57.041902Z","shell.execute_reply.started":"2025-07-17T14:42:15.449051Z","shell.execute_reply":"2025-07-17T14:51:57.041182Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 10. Load the Model with the Best Validation Accuracy","metadata":{"id":"hjEd_RQF1WQS"}},{"cell_type":"code","source":"# from keras.callbacks import ModelCheckpoint\n\n# # best method\n# checkpointer = ModelCheckpoint(filepath='aug_model_best.keras',\n#                                verbose=1,\n#                                save_best_only=True)\n\n\n# from tensorflow.keras.callbacks import ModelCheckpoint\n\n# batch_size = 5000\n# epochs = 100\n\n# # checkpointer = ModelCheckpoint(\n# #     filepath='aug_model_best.weights.h5',\n# #     verbose=1,\n# #     save_best_only=True,\n# #     save_weights_only=True\n# # )\n\n# model.fit(\n#     datagen_train.flow(x_train, y_train, batch_size=batch_size),\n#     steps_per_epoch=len(x_train) // batch_size,\n#     epochs=epochs,\n#     verbose=2,\n#     callbacks=checkpointer,\n#     validation_data=(x_valid, y_valid),\n#     validation_steps=len(x_valid) // batch_size\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T14:40:48.083799Z","iopub.execute_input":"2025-07-17T14:40:48.084078Z","iopub.status.idle":"2025-07-17T14:40:48.087855Z","shell.execute_reply.started":"2025-07-17T14:40:48.084056Z","shell.execute_reply":"2025-07-17T14:40:48.087031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load the weights that yielded the best validation accuracy\n# model.load_weights('aug_model_best.weights.h5') \nmodel.load_weights('aug_model_best.keras')","metadata":{"id":"ynUJ4kFd1WQS","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T14:52:11.679453Z","iopub.execute_input":"2025-07-17T14:52:11.680345Z","iopub.status.idle":"2025-07-17T14:52:11.837101Z","shell.execute_reply.started":"2025-07-17T14:52:11.680311Z","shell.execute_reply":"2025-07-17T14:52:11.836549Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 11. Calculate Classification Accuracy on Test Set","metadata":{"id":"7TO6JcKh1WQS"}},{"cell_type":"code","source":"# evaluate and print test accuracy\nscore = model.evaluate(x_test, y_test, verbose=1)\nprint('\\n', 'Test accuracy:', score[1])","metadata":{"id":"PldVmcoX1WQS","outputId":"58f4f561-1994-4362-910a-1aa64f45da8f","executionInfo":{"status":"ok","timestamp":1752675361078,"user_tz":-300,"elapsed":1109,"user":{"displayName":"Muhammad Mudasar Sabir","userId":"01867723878130094816"}},"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T14:52:13.332742Z","iopub.execute_input":"2025-07-17T14:52:13.333311Z","iopub.status.idle":"2025-07-17T14:52:15.17729Z","shell.execute_reply.started":"2025-07-17T14:52:13.333289Z","shell.execute_reply":"2025-07-17T14:52:15.17669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}